{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMi7hBIuCRWglIwS+X3Xow4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SubhamPanda2003/Machine_learning/blob/master/incomplete_parallelisation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1Luj38C5XSSs"
      },
      "outputs": [],
      "source": [
        "from multiprocessing import Process, Queue\n",
        "import difflib, random, time\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import pandas as pd\n",
        "import random\n",
        "from collections import Counter\n",
        "from sklearn import preprocessing\n",
        "from itertools import repeat\n",
        "import multiprocessing as mp\n",
        "import time\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from csv import writer\n",
        "#for plotting\n",
        "plt.style.use('ggplot')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomKNN:\n",
        "\tdef splitlist(self,inlist, chunksize):\n",
        "\t\treturn [inlist[x:x+chunksize] for x in range(0, len(inlist), chunksize)]\n",
        "\tdef __init__(self):\n",
        "\t\tself.accurate_predictions = 0\n",
        "\t\tself.total_predictions = 0\n",
        "\t\tself.accuracy = 0.0"
      ],
      "metadata": {
        "id": "qc-4g6a3XUIK"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(training_data, to_predict, k=15,arr={}):   \n",
        "\t\ts = time.perf_counter()                      #-----------------------------------value of k---------------------------------------------------\n",
        "\t\t# if len(training_data) >= k:\n",
        "\t\t# \tprint(\"K cannot be smaller than the total voting groups(ie. number of training data points)\")\n",
        "\t\t# \treturn\n",
        "\t\t\n",
        "\t\tdistributions = []\n",
        "\t\tfor group in training_data:\n",
        "\t\t\tfor features in training_data[group]:\n",
        "\t\t\t\t# Find euclidean distance using the numpy function\n",
        "\t\t\t\teuclidean_distance = np.linalg.norm(np.array(features)- np.array(to_predict))\n",
        "\t\t\t\tdistributions.append([euclidean_distance,group, features])\n",
        "\t\t# Find the k nearest neighbors\n",
        "\t\tresults = [i[1] for i in sorted(distributions)[:k]]\n",
        "\t\tres = [i[2] for i in sorted(distributions)[:k]]\n",
        "\t\t# Figure out which is the most common class amongst the neighbors.\n",
        "\t\twith open('event.csv', 'a') as f_object:\n",
        " \n",
        "    # Pass this file object to csv.writer()\n",
        "    # and get a writer object\n",
        "\t\t\twriter_object = writer(f_object)\n",
        " \n",
        "    # Pass the list as an argument into\n",
        "    # the writerow()\n",
        "\t\t\tfor list in res:\n",
        "\t\t\t\twriter_object.writerow(list)\n",
        "\t\t\twriter_object.writerow(results)\n",
        "\t\t\t# writer_object.writerow(to_predict)\n",
        "    # Close the file object\n",
        "\t\t\tf_object.close()\n",
        "\t\t# return results,to_predict"
      ],
      "metadata": {
        "id": "QbD8TaCbb8uI"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def SVM(to_predict):\n",
        "  data=pd.read_csv('event.csv')\n",
        "  # X=data\n",
        "  # for i in range(1):\n",
        "  #   X=data.drop(data.index[28*(i+1)])\n",
        "  # Y=data[data.index[28]]\n",
        "  X=data.drop(columns=['17'],axis=1)\n",
        "  Y=data['17']\n",
        "  scaler=StandardScaler()\n",
        "  scaler.fit(X)\n",
        "  model=svm.SVC(kernel='linear')\n",
        "  #training svm model with training data\n",
        "  model.fit(X,Y)\n",
        "  input_data=to_predict\n",
        "  input_data_as_numpy=np.asarray(input_data)\n",
        "  input_data_reshaped=input_data_as_numpy.reshape(1,-1)\n",
        "  input_data1=scaler.transform(input_data_reshaped)\n",
        "  prediction=model.predict(input_data1)\n",
        "\n",
        "  print(prediction)\n",
        "  \n"
      ],
      "metadata": {
        "id": "tU_OIKO1cPxW"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(test_set, training_set):\n",
        "\t\t# pool = mp.Pool(processes= 1)     #---------------------------------------------no of processs---------------------------------------------------------------------------------\n",
        "\n",
        "\t\tarr = {}\n",
        "\t\t\n",
        "\n",
        "\t\t# for group in test_set:\n",
        "\t\t# # s = time.perf_counter()\n",
        "\t\t\t\n",
        "\t\t# arr =  predict(training_set, test_set, 27) #-----------------------------------value of k---------------------------------------------------\n",
        "   \n",
        "\t\tSVM(test_set)\n",
        "\t\t"
      ],
      "metadata": {
        "id": "g7deLAXZZu1q"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mod_data(df):\n",
        "\tdf.replace('?', -999999, inplace = True)\n",
        "\tdf.replace('A', 0, inplace = True)\n",
        "\tdf.replace('B', 1, inplace = True)\n",
        "\tdf.replace('C', 2, inplace = True)\n",
        "\tdf.replace('D', 3, inplace = True)\n",
        "\tdf.replace('E', 4, inplace = True)\n",
        "\tdf.replace('F', 5, inplace = True)\n",
        "\tdf.replace('G', 6, inplace = True)\n",
        "\tdf.replace('H', 7, inplace = True)\n",
        "\tdf.replace('I', 8, inplace = True)\n",
        "\tdf.replace('J', 9, inplace = True)\n",
        "\tdf.replace('K', 10, inplace = True)\n",
        "\tdf.replace('L', 11, inplace = True)\n",
        "\tdf.replace('M', 12, inplace = True)\n",
        "\tdf.replace('N', 13, inplace = True)\n",
        "\tdf.replace('O', 14, inplace = True)\n",
        "\tdf.replace('P', 15, inplace = True)\n",
        "\tdf.replace('Q', 16, inplace = True)\n",
        "\tdf.replace('R', 17, inplace = True)\n",
        "\tdf.replace('S', 18, inplace = True)\n",
        "\tdf.replace('T', 19, inplace = True)\n",
        "\tdf.replace('U', 20, inplace = True)\n",
        "\tdf.replace('V', 21, inplace = True)\n",
        "\tdf.replace('W', 22, inplace = True)\n",
        "\tdf.replace('X', 23, inplace = True)\n",
        "\tdf.replace('Y', 24, inplace = True)\n",
        "\tdf.replace('Z', 25, inplace = True)\n",
        " "
      ],
      "metadata": {
        "id": "O0FQD6eqbEdo"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(r\"./letter1.csv\")\n",
        "mod_data(df)\n",
        "dataset = df.astype(float).values.tolist()\n",
        "\t\n",
        "\n",
        "\t\n",
        "#Shuffle the dataset\n",
        "random.shuffle(dataset)\n",
        "\n",
        "#20% of the available data will be used for testing\n",
        "test_size = 0.1\n",
        "\n",
        "\t#The keys of the dict are the classes that the data is classfied into\n",
        "training_set = {0: [], 1:[],2:[],3:[],4:[],5:[],6:[],7:[],8:[],9:[],10:[],11:[],12:[],13:[],14:[],15:[],16:[],17:[],18:[],19:[],20:[],21:[],22:[],23:[],24:[],25:[]}\n",
        "test_set = {0: [], 1:[],2:[],3:[],4:[],5:[],6:[],7:[],8:[],9:[],10:[],11:[],12:[],13:[],14:[],15:[],16:[],17:[],18:[],19:[],20:[],21:[],22:[],23:[],24:[],25:[]}\n",
        "\t\n",
        "\t#Split data into training and test for cross validation\n",
        "training_data = dataset[:-int(test_size * len(dataset))]\n",
        "test_data = dataset[-int(test_size * len(dataset)):]\n",
        "\t\n",
        "\t#Insert data into the training set\n",
        "for record in training_data:\n",
        "\t\ttraining_set[record[-1]].append(record[:-1]) # Append the list in the dict will all the elements of the record except the class\n",
        "\n",
        "\t#Insert data into the test set\n",
        "for record in test_data:\n",
        "\t\ttest_set[record[-1]].append(record[:-1]) # Append the list in the dict will all the elements of the record except the class\n",
        "df = pd.read_csv(r\"./letter1.csv\")\n",
        "mod_data(df)\n",
        "dataset = df.astype(float).values.tolist()\n",
        "training_set1 = {0: [], 1:[],2:[],3:[],4:[],5:[],6:[],7:[],8:[],9:[],10:[],11:[],12:[],13:[],14:[],15:[],16:[],17:[],18:[],19:[],20:[],21:[],22:[],23:[],24:[],25:[]}\n",
        "training_data1 = dataset\n",
        "for record in training_data1:\n",
        "\t\ttraining_set1[record[-1]].append(record[:-1]) # Append the list in the dict will all the elements of the record except the class\n",
        "s = time.perf_counter()\n",
        "print(type(training_set1))\n",
        "knn = CustomKNN()\n",
        "for record in test_set:\n",
        "  test(record, training_set1)\n",
        "e = time.perf_counter()\n",
        "\t\n",
        "print(\"Exec Time: \", e-s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "cl03p16ajKgY",
        "outputId": "9564414f-9604-48db-e16f-dc3daf4330dd"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-89a57fdeec54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mknn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomKNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrecord\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_set1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-968ed9fc5337>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(test_set, training_set)\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0;31m# arr =  predict(training_set, test_set, 27) #-----------------------------------value of k---------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 \u001b[0mSVM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-59-c14395d812eb>\u001b[0m in \u001b[0;36mSVM\u001b[0;34m(to_predict)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m#   X=data.drop(data.index[28*(i+1)])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;31m# Y=data[data.index[28]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'17'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'17'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mscaler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4911\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4912\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4913\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4914\u001b[0m         )\n\u001b[1;32m   4915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4150\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   4183\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4184\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4185\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4186\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6015\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6017\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6018\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6019\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['17'] not found in axis\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VMMG8MZPkttr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}